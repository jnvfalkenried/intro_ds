{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# [Introduction to Data Science](http://datascience-intro.github.io/1MS041-2023/)    \n",
    "## 1MS041, 2023 \n",
    "&copy;2023 Raazesh Sainudiin, Benny Avelin. [Attribution 4.0 International     (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. BASH Unix Shell \n",
    "\n",
    "\n",
    "1. Dropping into BASH (Unix Shell) and using basic Shell commands\n",
    "    * `pwd` --- print working directory\n",
    "    * `ls` --- list files in current working directory\n",
    "    * `mkdir` --- make directory\n",
    "    * `cd` --- change directory\n",
    "    * `man ls` --- manual pages for any command\n",
    "    * `head` --- show the first lines of a file\n",
    "2. Grabbing files from the internet using `curl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"95%\"\n",
       "            height=\"400\"\n",
       "            src=\"https://en.wikipedia.org/wiki/Bash_(Unix_shell)\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x6fffc4f0908>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def showURL(url, ht=500):\n",
    "    \"\"\"Return an IFrame of the url to show in notebook with height ht\"\"\"\n",
    "    from IPython.display import IFrame \n",
    "    return IFrame(url, width='95%', height=ht) \n",
    "showURL('https://en.wikipedia.org/wiki/Bash_(Unix_shell)',400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dropping into BASH (Unix Shell)\n",
    "\n",
    "Using `%%sh` in a code cell we can access the BASH (Unix Shell) command prompt.\n",
    "\n",
    "Let us `pwd` or print working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sage/Downloads/first_lecture_and_data\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-Probability.ipynb\n",
      "A01-BASH_Unix_Shell.ipynb\n",
      "data\n",
      "Utils.py\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# this is a comment in BASH shell as it is preceeded by '#'\n",
    "ls # list the contents of this working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir -p mydir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sage/Downloads/first_lecture_and_data/mydir\n",
      "total 4\n",
      "drwxr-xr-x+ 1 juvo5564 Domain Users 0 Sep  5 08:44 .\n",
      "drwx------+ 1 juvo5564 Domain Users 0 Sep  5 08:44 ..\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cd mydir\n",
    "pwd\n",
    "ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sage/Downloads/first_lecture_and_data\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Use the source\" by `man`-ning the unknown `command`\n",
    "\n",
    "By evaluating the next cell, you are using the `man`ual pages to find more about the command `ls`. You can learn more about any command called `command` by typing `man command` in the BASH shell.\n",
    "\n",
    "The output of the next cell with command `man ls` will look something like the following:\n",
    "\n",
    "```\n",
    "LS(1)                            User Commands                           LS(1)\n",
    "\n",
    "NAME\n",
    "       ls - list directory contents\n",
    "\n",
    "SYNOPSIS\n",
    "       ls [OPTION]... [FILE]...\n",
    "\n",
    "DESCRIPTION\n",
    "       List  information  about  the FILEs (the current directory by default).\n",
    "       Sort entries alphabetically if none of -cftuvSUX nor --sort  is  speci‐\n",
    "       fied.\n",
    "\n",
    "       Mandatory  arguments  to  long  options are mandatory for short options\n",
    "       too.\n",
    "\n",
    "       -a, --all\n",
    "              do not ignore entries starting with .\n",
    "\n",
    "       -A, --almost-all\n",
    "              do not list implied . and ..\n",
    "...\n",
    "...\n",
    "...\n",
    "   Exit status:\n",
    "       0      if OK,\n",
    "\n",
    "       1      if minor problems (e.g., cannot access subdirectory),\n",
    "\n",
    "       2      if serious trouble (e.g., cannot access command-line argument).\n",
    "\n",
    "AUTHOR\n",
    "       Written by Richard M. Stallman and David MacKenzie.\n",
    "\n",
    "REPORTING BUGS\n",
    "       GNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n",
    "       Report ls translation bugs to <http://translationproject.org/team/>\n",
    "\n",
    "COPYRIGHT\n",
    "       Copyright © 2017 Free Software Foundation, Inc.   License  GPLv3+:  GNU\n",
    "       GPL version 3 or later <http://gnu.org/licenses/gpl.html>.\n",
    "       This  is  free  software:  you  are free to change and redistribute it.\n",
    "       There is NO WARRANTY, to the extent permitted by law.\n",
    "\n",
    "SEE ALSO\n",
    "       Full documentation at: <http://www.gnu.org/software/coreutils/ls>\n",
    "       or available locally via: info '(coreutils) ls invocation'\n",
    "\n",
    "GNU coreutils 8.28               January 2018                            LS(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS(1)                            User Commands                           LS(1)\n",
      "\n",
      "NAME\n",
      "       ls - list directory contents\n",
      "\n",
      "SYNOPSIS\n",
      "       ls [OPTION]... [FILE]...\n",
      "\n",
      "DESCRIPTION\n",
      "       List  information  about  the FILEs (the current directory by default).\n",
      "       Sort entries alphabetically if none of -cftuvSUX nor --sort  is  speci‐\n",
      "       fied.\n",
      "\n",
      "       Mandatory  arguments  to  long  options are mandatory for short options\n",
      "       too.\n",
      "\n",
      "       -a, --all\n",
      "              do not ignore entries starting with .\n",
      "\n",
      "       -A, --almost-all\n",
      "              do not list implied . and ..\n",
      "\n",
      "       --author\n",
      "              with -l, print the author of each file\n",
      "\n",
      "       -b, --escape\n",
      "              print C-style escapes for nongraphic characters\n",
      "\n",
      "       --block-size=SIZE\n",
      "              scale sizes by SIZE before printing them; e.g., '--block-size=M'\n",
      "              prints sizes in units of 1,048,576 bytes; see SIZE format below\n",
      "\n",
      "       -B, --ignore-backups\n",
      "              do not list implied entries ending with ~\n",
      "\n",
      "       -c     with -lt: sort by, and show, ctime (time of last modification of\n",
      "              file status information); with -l: show ctime and sort by  name;\n",
      "              otherwise: sort by ctime, newest first\n",
      "\n",
      "       -C     list entries by columns\n",
      "\n",
      "       --color[=WHEN]\n",
      "              colorize  the output; WHEN can be 'always' (default if omitted),\n",
      "              'auto', or 'never'; more info below\n",
      "\n",
      "       -d, --directory\n",
      "              list directories themselves, not their contents\n",
      "\n",
      "       -D, --dired\n",
      "              generate output designed for Emacs' dired mode\n",
      "\n",
      "       -f     do not sort, enable -aU, disable -ls --color\n",
      "\n",
      "       -F, --classify\n",
      "              append indicator (one of */=>@|) to entries\n",
      "\n",
      "       --file-type\n",
      "              likewise, except do not append '*'\n",
      "\n",
      "       --format=WORD\n",
      "              across -x, commas -m, horizontal -x, long -l, single-column  -1,\n",
      "              verbose -l, vertical -C\n",
      "\n",
      "       --full-time\n",
      "              like -l --time-style=full-iso\n",
      "\n",
      "       -g     like -l, but do not list owner\n",
      "\n",
      "       --group-directories-first\n",
      "              group directories before files;\n",
      "\n",
      "              can   be  augmented  with  a  --sort  option,  but  any  use  of\n",
      "              --sort=none (-U) disables grouping\n",
      "\n",
      "       -G, --no-group\n",
      "              in a long listing, don't print group names\n",
      "\n",
      "       -h, --human-readable\n",
      "              with -l and/or -s, print human readable sizes (e.g., 1K 234M 2G)\n",
      "\n",
      "       --si   likewise, but use powers of 1000 not 1024\n",
      "\n",
      "       -H, --dereference-command-line\n",
      "              follow symbolic links listed on the command line\n",
      "\n",
      "       --dereference-command-line-symlink-to-dir\n",
      "              follow each command line symbolic link\n",
      "\n",
      "              that points to a directory\n",
      "\n",
      "       --hide=PATTERN\n",
      "              do not list implied entries matching shell  PATTERN  (overridden\n",
      "              by -a or -A)\n",
      "\n",
      "       --indicator-style=WORD\n",
      "              append indicator with style WORD to entry names: none (default),\n",
      "              slash (-p), file-type (--file-type), classify (-F)\n",
      "\n",
      "       -i, --inode\n",
      "              print the index number of each file\n",
      "\n",
      "       -I, --ignore=PATTERN\n",
      "              do not list implied entries matching shell PATTERN\n",
      "\n",
      "       -k, --kibibytes\n",
      "              default to 1024-byte blocks for disk usage\n",
      "\n",
      "       -l     use a long listing format\n",
      "\n",
      "       -L, --dereference\n",
      "              when showing file information for a symbolic link, show informa‐\n",
      "              tion  for  the file the link references rather than for the link\n",
      "              itself\n",
      "\n",
      "       -m     fill width with a comma separated list of entries\n",
      "\n",
      "       -n, --numeric-uid-gid\n",
      "              like -l, but list numeric user and group IDs\n",
      "\n",
      "       -N, --literal\n",
      "              print entry names without quoting\n",
      "\n",
      "       -o     like -l, but do not list group information\n",
      "\n",
      "       -p, --indicator-style=slash\n",
      "              append / indicator to directories\n",
      "\n",
      "       -q, --hide-control-chars\n",
      "              print ? instead of nongraphic characters\n",
      "\n",
      "       --show-control-chars\n",
      "              show nongraphic characters as-is (the default, unless program is\n",
      "              'ls' and output is a terminal)\n",
      "\n",
      "       -Q, --quote-name\n",
      "              enclose entry names in double quotes\n",
      "\n",
      "       --quoting-style=WORD\n",
      "              use  quoting style WORD for entry names: literal, locale, shell,\n",
      "              shell-always, shell-escape, shell-escape-always, c, escape\n",
      "\n",
      "       -r, --reverse\n",
      "              reverse order while sorting\n",
      "\n",
      "       -R, --recursive\n",
      "              list subdirectories recursively\n",
      "\n",
      "       -s, --size\n",
      "              print the allocated size of each file, in blocks\n",
      "\n",
      "       -S     sort by file size, largest first\n",
      "\n",
      "       --sort=WORD\n",
      "              sort by WORD instead of name: none (-U), size (-S),  time  (-t),\n",
      "              version (-v), extension (-X)\n",
      "\n",
      "       --time=WORD\n",
      "              with -l, show time as WORD instead of default modification time:\n",
      "              atime or access or use (-u); ctime  or  status  (-c);  also  use\n",
      "              specified time as sort key if --sort=time (newest first)\n",
      "\n",
      "       --time-style=STYLE\n",
      "              with  -l, show times using style STYLE: full-iso, long-iso, iso,\n",
      "              locale, or +FORMAT; FORMAT is interpreted  like  in  'date';  if\n",
      "              FORMAT  is  FORMAT1<newline>FORMAT2,  then  FORMAT1  applies  to\n",
      "              non-recent files and FORMAT2 to recent files; if STYLE  is  pre‐\n",
      "              fixed  with  'posix-', STYLE takes effect only outside the POSIX\n",
      "              locale\n",
      "\n",
      "       -t     sort by modification time, newest first\n",
      "\n",
      "       -T, --tabsize=COLS\n",
      "              assume tab stops at each COLS instead of 8\n",
      "\n",
      "       -u     with -lt: sort by, and show, access time; with -l:  show  access\n",
      "              time  and  sort  by name; otherwise: sort by access time, newest\n",
      "              first\n",
      "\n",
      "       -U     do not sort; list entries in directory order\n",
      "\n",
      "       -v     natural sort of (version) numbers within text\n",
      "\n",
      "       -w, --width=COLS\n",
      "              set output width to COLS.  0 means no limit\n",
      "\n",
      "       -x     list entries by lines instead of by columns\n",
      "\n",
      "       -X     sort alphabetically by entry extension\n",
      "\n",
      "       -Z, --context\n",
      "              print any security context of each file\n",
      "\n",
      "       -1     list one file per line.  Avoid '\\n' with -q or -b\n",
      "\n",
      "       --append-exe\n",
      "              append .exe if cygwin magic was needed\n",
      "\n",
      "       --help display this help and exit\n",
      "\n",
      "       --version\n",
      "              output version information and exit\n",
      "\n",
      "       The SIZE argument is an integer and  optional  unit  (example:  10K  is\n",
      "       10*1024).   Units  are  K,M,G,T,P,E,Z,Y  (powers  of 1024) or KB,MB,...\n",
      "       (powers of 1000).\n",
      "\n",
      "       Using color to distinguish file types is disabled both by  default  and\n",
      "       with  --color=never.  With --color=auto, ls emits color codes only when\n",
      "       standard output is connected to a terminal.  The LS_COLORS  environment\n",
      "       variable can change the settings.  Use the dircolors command to set it.\n",
      "\n",
      "   Exit status:\n",
      "       0      if OK,\n",
      "\n",
      "       1      if minor problems (e.g., cannot access subdirectory),\n",
      "\n",
      "       2      if serious trouble (e.g., cannot access command-line argument).\n",
      "\n",
      "AUTHOR\n",
      "       Written by Richard M. Stallman and David MacKenzie.\n",
      "\n",
      "REPORTING BUGS\n",
      "       GNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n",
      "       Report ls translation bugs to <http://translationproject.org/team/>\n",
      "\n",
      "SEE ALSO\n",
      "       Full documentation at: <http://www.gnu.org/software/coreutils/ls>\n",
      "       or available locally via: info '(coreutils) ls invocation'\n",
      "\n",
      "       Packaged by Cygwin (8.26-2)\n",
      "       Copyright © 2016 Free Software Foundation, Inc.\n",
      "       License   GPLv3+:  GNU  GPL  version  3  or  later  <http://gnu.org/li‐\n",
      "       censes/gpl.html>.\n",
      "       This is free software: you are free to change and redistribute it.\n",
      "       There is NO WARRANTY, to the extent permitted by law.\n",
      "\n",
      "GNU coreutils 8.26               November 2016                           LS(1)\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "## uncomment by removing '#' in the next line and try executing this cell\n",
    "man ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grabbing files from internet using curl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100 29323  100 29323    0     0  52362      0 --:--:-- --:--:-- --:--:-- 52362\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cd mydir\n",
    "curl -O http://lamastex.org/datasets/public/SOU/sou/20170228.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170228.txt\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ls mydir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald J. Trump \n",
      "\n",
      "February 28, 2017 \n",
      "Thank you very much. Mr. Speaker, Mr. Vice President, members of Congress, the first lady of the United States ... \n",
      "... and citizens of America, tonight, as we mark the conclusion of our celebration of Black History Month, we are reminded of our nation's path toward civil rights and the work that still remains to be done. \n",
      "Recent threats ... \n",
      "Recent threats targeting Jewish community centers and vandalism of Jewish cemeteries, as well as last week's shooting in Kansas City, remind us that while we may be a nation divided on policies, we are a country that stands united in condemning hate and evil in all of its very ugly forms. \n",
      "Each American generation passes the torch of truth, liberty and justice, in an unbroken chain all the way down to the present. That torch is now in our hands. And we will use it to light up the world. \n",
      "I am here tonight to deliver a message of unity and strength, and it is a message deeply delivered from my heart. A new chapter ... \n",
      "... of American greatness is now beginning. A new national pride is sweeping across our nation. And a new surge of optimism is placing impossible dreams firmly within our grasp. What we are witnessing today is the renewal of the American spirit. Our allies will find that America is once again ready to lead. \n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cd mydir/\n",
    "head 20170228.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To have more fun with all SOU addresses\n",
    "Do the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  2 3566k    2  105k    0     0   114k      0  0:00:31 --:--:--  0:00:31  114k\r",
      "  6 3566k    6  227k    0     0   114k      0  0:00:31  0:00:01  0:00:30  114k\r",
      " 10 3566k   10  368k    0     0   126k      0  0:00:28  0:00:02  0:00:26  125k\r",
      " 12 3566k   12  447k    0     0   113k      0  0:00:31  0:00:03  0:00:28  113k\r",
      " 14 3566k   14  524k    0     0   106k      0  0:00:33  0:00:04  0:00:29  106k\r",
      " 16 3566k   16  604k    0     0   102k      0  0:00:34  0:00:05  0:00:29  100k\r",
      " 19 3566k   19  706k    0     0   102k      0  0:00:34  0:00:06  0:00:28 99788\r",
      " 22 3566k   22  812k    0     0   103k      0  0:00:34  0:00:07  0:00:27 91784\r",
      " 25 3566k   25  917k    0     0   102k      0  0:00:34  0:00:08  0:00:26 95918\r",
      " 29 3566k   29 1040k    0     0   104k      0  0:00:34  0:00:09  0:00:25  102k\r",
      " 32 3566k   32 1151k    0     0   105k      0  0:00:33  0:00:10  0:00:23  108k\r",
      " 36 3566k   36 1297k    0     0   108k      0  0:00:32  0:00:11  0:00:21  117k\r",
      " 39 3566k   39 1414k    0     0   109k      0  0:00:32  0:00:12  0:00:20  120k\r",
      " 43 3566k   43 1562k    0     0   112k      0  0:00:31  0:00:13  0:00:18  130k\r",
      " 48 3566k   48 1727k    0     0   115k      0  0:00:30  0:00:14  0:00:16  139k\r",
      " 52 3566k   52 1878k    0     0   118k      0  0:00:30  0:00:15  0:00:15  145k\r",
      " 57 3566k   57 2045k    0     0   121k      0  0:00:29  0:00:16  0:00:13  151k\r",
      " 61 3566k   61 2209k    0     0   123k      0  0:00:28  0:00:17  0:00:11  159k\r",
      " 67 3566k   67 2406k    0     0   127k      0  0:00:28  0:00:18  0:00:10  167k\r",
      " 72 3566k   72 2577k    0     0   129k      0  0:00:27  0:00:19  0:00:08  170k\r",
      " 78 3566k   78 2782k    0     0   133k      0  0:00:26  0:00:20  0:00:06  181k\r",
      " 84 3566k   84 3002k    0     0   136k      0  0:00:26  0:00:21  0:00:05  189k\r",
      " 89 3566k   89 3204k    0     0   139k      0  0:00:25  0:00:22  0:00:03  197k\r",
      " 96 3566k   96 3424k    0     0   143k      0  0:00:24  0:00:23  0:00:01  206k\r",
      "100 3566k  100 3566k    0     0   145k      0  0:00:24  0:00:24 --:--:--  212k\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "mkdir -p mydir # first create a directory called 'mydir'\n",
    "cd mydir # change into this mydir directory\n",
    "rm -f sou.tar.gz # remove any file in mydir called sou.tar.gz\n",
    "curl -O http://lamastex.org/datasets/public/SOU/sou.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sage/Downloads/first_lecture_and_data\n",
      "total 3.6M\n",
      "-rw-r--r--+ 1 juvo5564 Domain Users  29K Sep  5 08:50 20170228.txt\n",
      "-rw-r--r--+ 1 juvo5564 Domain Users 3.5M Sep  5 08:52 sou.tar.gz\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pwd\n",
    "ls -lh mydir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sou/\n",
      "sou/18111105.txt\n",
      "sou/20040120.txt\n",
      "sou/19061203.txt\n",
      "sou/18411207.txt\n",
      "sou/19091207.txt\n",
      "sou/18701205.txt\n",
      "sou/19410106.txt\n",
      "sou/18571208.txt\n",
      "sou/18891203.txt\n",
      "sou/18341201.txt\n",
      "sou/19660112.txt\n",
      "sou/17981208.txt\n",
      "sou/19610130.txt\n",
      "sou/18140920.txt\n",
      "sou/18011208.txt\n",
      "sou/18811206.txt\n",
      "sou/18281202.txt\n",
      "sou/19840125.txt\n",
      "sou/18611203.txt\n",
      "sou/18731201.txt\n",
      "sou/19400103.txt\n",
      "sou/19630114.txt\n",
      "sou/19281204.txt\n",
      "sou/19221208.txt\n",
      "sou/19031207.txt\n",
      "sou/18681209.txt\n",
      "sou/18431206.txt\n",
      "sou/18861206.txt\n",
      "sou/19261207.txt\n",
      "sou/19271206.txt\n",
      "sou/19141208.txt\n",
      "sou/18791201.txt\n",
      "sou/19131202.txt\n",
      "sou/19041206.txt\n",
      "sou/18001111.txt\n",
      "sou/18041108.txt\n",
      "sou/20010227.txt\n",
      "sou/18621201.txt\n",
      "sou/19251208.txt\n",
      "sou/19700122.txt\n",
      "sou/19790125.txt\n",
      "sou/19870127.txt\n",
      "sou/20050202.txt\n",
      "sou/18331203.txt\n",
      "sou/17961207.txt\n",
      "sou/18021215.txt\n",
      "sou/18771203.txt\n",
      "sou/19890209.txt\n",
      "sou/18301206.txt\n",
      "sou/18121104.txt\n",
      "sou/19580109.txt\n",
      "sou/20110125.txt\n",
      "sou/19450106.txt\n",
      "sou/18031017.txt\n",
      "sou/19301202.txt\n",
      "sou/18661203.txt\n",
      "sou/19520109.txt\n",
      "sou/19620111.txt\n",
      "sou/18531205.txt\n",
      "sou/19610112.txt\n",
      "sou/19430107.txt\n",
      "sou/19960123.txt\n",
      "sou/17911025.txt\n",
      "sou/18211203.txt\n",
      "sou/18951207.txt\n",
      "sou/18901201.txt\n",
      "sou/18721202.txt\n",
      "sou/20140128.txt\n",
      "sou/18361205.txt\n",
      "sou/18101205.txt\n",
      "sou/18081108.txt\n",
      "sou/18961204.txt\n",
      "sou/18871206.txt\n",
      "sou/18781202.txt\n",
      "sou/19480107.txt\n",
      "sou/19001203.txt\n",
      "sou/18421206.txt\n",
      "sou/18241207.txt\n",
      "sou/18131207.txt\n",
      "sou/19500104.txt\n",
      "sou/20010920.txt\n",
      "sou/19940125.txt\n",
      "sou/19850206.txt\n",
      "sou/18541204.txt\n",
      "sou/17921106.txt\n",
      "sou/19800121.txt\n",
      "sou/19311208.txt\n",
      "sou/18461208.txt\n",
      "sou/19161205.txt\n",
      "sou/19121203.txt\n",
      "sou/19370106.txt\n",
      "sou/19151207.txt\n",
      "sou/19051205.txt\n",
      "sou/19021202.txt\n",
      "sou/18321204.txt\n",
      "sou/18671203.txt\n",
      "sou/18651204.txt\n",
      "sou/19510108.txt\n",
      "sou/18581206.txt\n",
      "sou/18161203.txt\n",
      "sou/19390104.txt\n",
      "sou/19321206.txt\n",
      "sou/18641206.txt\n",
      "sou/20070123.txt\n",
      "sou/18691206.txt\n",
      "sou/17991203.txt\n",
      "sou/18551231.txt\n",
      "sou/19440111.txt\n",
      "sou/19910129.txt\n",
      "sou/18921206.txt\n",
      "sou/18061202.txt\n",
      "sou/19470106.txt\n",
      "sou/19590109.txt\n",
      "sou/18151205.txt\n",
      "sou/18751207.txt\n",
      "sou/18981205.txt\n",
      "sou/20090224.txt\n",
      "sou/18071027.txt\n",
      "sou/18171212.txt\n",
      "sou/18821204.txt\n",
      "sou/19211206.txt\n",
      "sou/18371205.txt\n",
      "sou/19181202.txt\n",
      "sou/19720120.txt\n",
      "sou/18601203.txt\n",
      "sou/19530107.txt\n",
      "sou/18741207.txt\n",
      "sou/19460121.txt\n",
      "sou/19350104.txt\n",
      "sou/19201207.txt\n",
      "sou/18591219.txt\n",
      "sou/18221203.txt\n",
      "sou/19231206.txt\n",
      "sou/19730202.txt\n",
      "sou/19291203.txt\n",
      "sou/19820126.txt\n",
      "sou/20060131.txt\n",
      "sou/18501202.txt\n",
      "sou/17931203.txt\n",
      "sou/18711204.txt\n",
      "sou/18441203.txt\n",
      "sou/17900108.txt\n",
      "sou/18561202.txt\n",
      "sou/18381203.txt\n",
      "sou/19071203.txt\n",
      "sou/19570110.txt\n",
      "sou/19171204.txt\n",
      "sou/18181116.txt\n",
      "sou/19420106.txt\n",
      "sou/18201114.txt\n",
      "sou/20130212.txt\n",
      "sou/20030128.txt\n",
      "sou/19340103.txt\n",
      "sou/19970204.txt\n",
      "sou/19810116.txt\n",
      "sou/18841201.txt\n",
      "sou/19101206.txt\n",
      "sou/18351207.txt\n",
      "sou/17951208.txt\n",
      "sou/19530202.txt\n",
      "sou/18971206.txt\n",
      "sou/18231202.txt\n",
      "sou/18831204.txt\n",
      "sou/19490105.txt\n",
      "sou/18991205.txt\n",
      "sou/18391202.txt\n",
      "sou/18481205.txt\n",
      "sou/18631208.txt\n",
      "sou/19930217.txt\n",
      "sou/19111205.txt\n",
      "sou/19740130.txt\n",
      "sou/20160112.txt\n",
      "sou/19880125.txt\n",
      "sou/19690114.txt\n",
      "sou/19360103.txt\n",
      "sou/20120124.txt\n",
      "sou/18091129.txt\n",
      "sou/19680117.txt\n",
      "sou/18851208.txt\n",
      "sou/20100127.txt\n",
      "sou/19191202.txt\n",
      "sou/19670110.txt\n",
      "sou/18451202.txt\n",
      "sou/19241203.txt\n",
      "sou/20080128.txt\n",
      "sou/18291208.txt\n",
      "sou/19980127.txt\n",
      "sou/18401205.txt\n",
      "sou/18471207.txt\n",
      "sou/19540107.txt\n",
      "sou/18191207.txt\n",
      "sou/18801206.txt\n",
      "sou/18491204.txt\n",
      "sou/18881203.txt\n",
      "sou/19950124.txt\n",
      "sou/19380103.txt\n",
      "sou/18761205.txt\n",
      "sou/18931203.txt\n",
      "sou/18051203.txt\n",
      "sou/18271204.txt\n",
      "sou/19900131.txt\n",
      "sou/18941202.txt\n",
      "sou/20150120.txt\n",
      "sou/17941119.txt\n",
      "sou/18261205.txt\n",
      "sou/19710122.txt\n",
      "sou/17901208.txt\n",
      "sou/19081208.txt\n",
      "sou/19550106.txt\n",
      "sou/17971122.txt\n",
      "sou/19560105.txt\n",
      "sou/19640108.txt\n",
      "sou/20020129.txt\n",
      "sou/19920128.txt\n",
      "sou/18511202.txt\n",
      "sou/18311206.txt\n",
      "sou/19770112.txt\n",
      "sou/18521206.txt\n",
      "sou/19760119.txt\n",
      "sou/18251206.txt\n",
      "sou/19860204.txt\n",
      "sou/19830125.txt\n",
      "sou/19780119.txt\n",
      "sou/19650104.txt\n",
      "sou/19990119.txt\n",
      "sou/20000127.txt\n",
      "sou/19600107.txt\n",
      "sou/19011203.txt\n",
      "sou/19750115.txt\n",
      "sou/18911209.txt\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cd mydir \n",
    "tar zxvf sou.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the above two cells, you should have all the SOU (State of Union) addresses. By evaluating the next cell's `ls ...` command you should see the SOU files like the following:\n",
    "\n",
    "```\n",
    "total 11M\n",
    "-rw------- 1 raazesh raazesh 6.6K Feb 18  2016 17900108.txt\n",
    "-rw------- 1 raazesh raazesh 8.3K Feb 18  2016 17901208.txt\n",
    "-rw------- 1 raazesh raazesh  14K Feb 18  2016 17911025.txt\n",
    "...\n",
    "...\n",
    "...\n",
    "-rw------- 1 raazesh raazesh  39K Feb 18  2016 20140128.txt\n",
    "-rw------- 1 raazesh raazesh  38K Feb 18  2016 20150120.txt\n",
    "-rw------- 1 raazesh raazesh  31K Feb 18  2016 20160112.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 11M\n",
      "-rw-------+ 1 juvo5564 Domain Users 6.6K Feb 18  2016 17900108.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 8.3K Feb 18  2016 17901208.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  14K Feb 18  2016 17911025.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  13K Feb 18  2016 17921106.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  12K Feb 18  2016 17931203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  18K Feb 18  2016 17941119.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  13K Feb 18  2016 17951208.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  17K Feb 18  2016 17961207.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  13K Feb 18  2016 17971122.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  14K Feb 18  2016 17981208.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 9.1K Feb 18  2016 17991203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 8.2K Feb 18  2016 18001111.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  19K Feb 18  2016 18011208.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  13K Feb 18  2016 18021215.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  14K Feb 18  2016 18031017.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  13K Feb 18  2016 18041108.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  17K Feb 18  2016 18051203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  17K Feb 18  2016 18061202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  14K Feb 18  2016 18071027.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  16K Feb 18  2016 18081108.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  11K Feb 18  2016 18091129.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  15K Feb 18  2016 18101205.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  14K Feb 18  2016 18111105.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  20K Feb 18  2016 18121104.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  20K Feb 18  2016 18131207.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  13K Feb 18  2016 18140920.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  19K Feb 18  2016 18151205.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  20K Feb 18  2016 18161203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  26K Feb 18  2016 18171212.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  26K Feb 18  2016 18181116.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  28K Feb 18  2016 18191207.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  21K Feb 18  2016 18201114.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  34K Feb 18  2016 18211203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  28K Feb 18  2016 18221203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  38K Feb 18  2016 18231202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  49K Feb 18  2016 18241207.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  53K Feb 18  2016 18251206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  46K Feb 18  2016 18261205.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  42K Feb 18  2016 18271204.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  44K Feb 18  2016 18281202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  62K Feb 18  2016 18291208.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  89K Feb 18  2016 18301206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  42K Feb 18  2016 18311206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  46K Feb 18  2016 18321204.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  46K Feb 18  2016 18331203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  79K Feb 18  2016 18341201.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  63K Feb 18  2016 18351207.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  72K Feb 18  2016 18361205.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  68K Feb 18  2016 18371205.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  69K Feb 18  2016 18381203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  79K Feb 18  2016 18391202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  54K Feb 18  2016 18401205.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  48K Feb 18  2016 18411207.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  49K Feb 18  2016 18421206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  47K Feb 18  2016 18431206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  55K Feb 18  2016 18441203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  94K Feb 18  2016 18451202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 106K Feb 18  2016 18461208.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  95K Feb 18  2016 18471207.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 125K Feb 18  2016 18481205.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  45K Feb 18  2016 18491204.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  49K Feb 18  2016 18501202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  78K Feb 18  2016 18511202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  59K Feb 18  2016 18521206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  57K Feb 18  2016 18531205.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  61K Feb 18  2016 18541204.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  69K Feb 18  2016 18551231.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  63K Feb 18  2016 18561202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  81K Feb 18  2016 18571208.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  97K Feb 18  2016 18581206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  73K Feb 18  2016 18591219.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  83K Feb 18  2016 18601203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  41K Feb 18  2016 18611203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  49K Feb 18  2016 18621201.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  37K Feb 18  2016 18631208.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  36K Feb 18  2016 18641206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  54K Feb 18  2016 18651204.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  44K Feb 18  2016 18661203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  70K Feb 18  2016 18671203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  60K Feb 18  2016 18681209.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  46K Feb 18  2016 18691206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  51K Feb 18  2016 18701205.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  38K Feb 18  2016 18711204.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  24K Feb 18  2016 18721202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  59K Feb 18  2016 18731201.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  54K Feb 18  2016 18741207.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  72K Feb 18  2016 18751207.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  40K Feb 18  2016 18761205.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  48K Feb 18  2016 18771203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  48K Feb 18  2016 18781202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  70K Feb 18  2016 18791201.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  41K Feb 18  2016 18801206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  24K Feb 18  2016 18811206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  19K Feb 18  2016 18821204.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  24K Feb 18  2016 18831204.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  54K Feb 18  2016 18841201.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 119K Feb 18  2016 18851208.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  91K Feb 18  2016 18861206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  31K Feb 18  2016 18871206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  55K Feb 18  2016 18881203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  77K Feb 18  2016 18891203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  68K Feb 18  2016 18901201.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  95K Feb 18  2016 18911209.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  80K Feb 18  2016 18921206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  75K Feb 18  2016 18931203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  96K Feb 18  2016 18941202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  88K Feb 18  2016 18951207.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  93K Feb 18  2016 18961204.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  72K Feb 18  2016 18971206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 121K Feb 18  2016 18981205.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  91K Feb 18  2016 18991205.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 116K Feb 18  2016 19001203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 114K Feb 18  2016 19011203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  57K Feb 18  2016 19021202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  89K Feb 18  2016 19031207.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 102K Feb 18  2016 19041206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 144K Feb 18  2016 19051205.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 135K Feb 18  2016 19061203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 159K Feb 18  2016 19071203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 113K Feb 18  2016 19081208.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  83K Feb 18  2016 19091207.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  42K Feb 18  2016 19101206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 141K Feb 18  2016 19111205.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 150K Feb 18  2016 19121203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  21K Feb 18  2016 19131202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  25K Feb 18  2016 19141208.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  44K Feb 18  2016 19151207.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  13K Feb 18  2016 19161205.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  22K Feb 18  2016 19171204.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  31K Feb 18  2016 19181202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  28K Feb 18  2016 19191202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  16K Feb 18  2016 19201207.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  34K Feb 18  2016 19211206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  35K Feb 18  2016 19221208.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  41K Feb 18  2016 19231206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  42K Feb 18  2016 19241203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  65K Feb 18  2016 19251208.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  62K Feb 18  2016 19261207.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  53K Feb 18  2016 19271206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  49K Feb 18  2016 19281204.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  68K Feb 18  2016 19291203.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  29K Feb 18  2016 19301202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  36K Feb 18  2016 19311208.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  26K Feb 18  2016 19321206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  14K Feb 18  2016 19340103.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  21K Feb 18  2016 19350104.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  22K Feb 18  2016 19360103.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  17K Feb 18  2016 19370106.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  28K Feb 18  2016 19380103.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  23K Feb 18  2016 19390104.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  19K Feb 18  2016 19400103.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  19K Feb 18  2016 19410106.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  20K Feb 18  2016 19420106.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  26K Feb 18  2016 19430107.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  22K Feb 18  2016 19440111.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  48K Feb 18  2016 19450106.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 171K Feb 18  2016 19460121.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  37K Feb 18  2016 19470106.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  30K Feb 18  2016 19480107.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  21K Feb 18  2016 19490105.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  30K Feb 18  2016 19500104.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  23K Feb 18  2016 19510108.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  30K Feb 18  2016 19520109.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  56K Feb 18  2016 19530107.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  43K Feb 18  2016 19530202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  37K Feb 18  2016 19540107.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  46K Feb 18  2016 19550106.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  51K Feb 18  2016 19560105.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  26K Feb 18  2016 19570110.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  30K Feb 18  2016 19580109.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  30K Feb 18  2016 19590109.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  35K Feb 18  2016 19600107.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  40K Feb 18  2016 19610112.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  31K Feb 18  2016 19610130.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  39K Feb 18  2016 19620111.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  31K Feb 18  2016 19630114.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  19K Feb 18  2016 19640108.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  25K Feb 18  2016 19650104.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  30K Feb 18  2016 19660112.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  41K Feb 18  2016 19670110.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  29K Feb 18  2016 19680117.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  24K Feb 18  2016 19690114.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  25K Feb 18  2016 19700122.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  26K Feb 18  2016 19710122.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  23K Feb 18  2016 19720120.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 9.7K Feb 18  2016 19730202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  29K Feb 18  2016 19740130.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  25K Feb 18  2016 19750115.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  30K Feb 18  2016 19760119.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  28K Feb 18  2016 19770112.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  26K Feb 18  2016 19780119.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  20K Feb 18  2016 19790125.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  20K Feb 18  2016 19800121.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users 213K Feb 18  2016 19810116.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  31K Feb 18  2016 19820126.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  33K Feb 18  2016 19830125.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  30K Feb 18  2016 19840125.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  25K Feb 18  2016 19850206.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  20K Feb 18  2016 19860204.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  22K Feb 18  2016 19870127.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  28K Feb 18  2016 19880125.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  28K Feb 18  2016 19890209.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  21K Feb 18  2016 19900131.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  22K Feb 18  2016 19910129.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  27K Feb 18  2016 19920128.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  39K Feb 18  2016 19930217.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  42K Feb 18  2016 19940125.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  51K Feb 18  2016 19950124.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  36K Feb 18  2016 19960123.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  39K Feb 18  2016 19970204.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  42K Feb 18  2016 19980127.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  43K Feb 18  2016 19990119.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  44K Feb 18  2016 20000127.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  25K Feb 18  2016 20010227.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  17K Feb 18  2016 20010920.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  23K Feb 18  2016 20020129.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  32K Feb 18  2016 20030128.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  30K Feb 18  2016 20040120.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  30K Feb 18  2016 20050202.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  31K Feb 18  2016 20060131.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  32K Feb 18  2016 20070123.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  34K Feb 18  2016 20080128.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  33K Feb 18  2016 20090224.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  41K Feb 18  2016 20100127.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  39K Feb 18  2016 20110125.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  40K Feb 18  2016 20120124.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  37K Feb 18  2016 20130212.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  39K Feb 18  2016 20140128.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  38K Feb 18  2016 20150120.txt\n",
      "-rw-------+ 1 juvo5564 Domain Users  31K Feb 18  2016 20160112.txt\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ls -lh mydir/sou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington \n",
      "\n",
      "January 8, 1790 \n",
      "Fellow-Citizens of the Senate and House of Representatives: \n",
      "I embrace with great satisfaction the opportunity which now presents itself of congratulating you on the present favorable prospects of our public affairs. The recent accession of the important state of North Carolina to the Constitution of the United States (of which official information has been received), the rising credit and respectability of our country, the general and increasing good will toward the government of the Union, and the concord, peace, and plenty with which we are blessed are circumstances auspicious in an eminent degree to our national prosperity. \n",
      "In resuming your consultations for the general good you can not but derive encouragement from the reflection that the measures of the last session have been as satisfactory to your constituents as the novelty and difficulty of the work allowed you to hope. Still further to realize their expectations and to secure the blessings which a gracious Providence has placed within our reach will in the course of the present important session call for the cool and deliberate exertion of your patriotism, firmness, and wisdom. \n",
      "Among the many interesting objects which will engage your attention that of providing for the common defense will merit particular regard. To be prepared for war is one of the most effectual means of preserving peace. \n",
      "A free people ought not only to be armed, but disciplined; to which end a uniform and well-digested plan is requisite; and their safety and interest require that they should promote such manufactories as tend to render them independent of others for essential, particularly military, supplies. \n",
      "The proper establishment of the troops which may be deemed indispensable will be entitled to mature consideration. In the arrangements which may be made respecting it it will be of importance to conciliate the comfortable support of the officers and soldiers with a due regard to economy. \n",
      "There was reason to hope that the pacific measures adopted with regard to certain hostile tribes of Indians would have relieved the inhabitants of our southern and western frontiers from their depredations, but you will perceive from the information contained in the papers which I shall direct to be laid before you (comprehending a communication from the Commonwealth of Virginia) that we ought to be prepared to afford protection to those parts of the Union, and, if necessary, to punish aggressors. \n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "head mydir/sou/17900108.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama \n",
      "\n",
      "January 12, 2016 \n",
      "Mr. Speaker, Mr. Vice President, Members of Congress, my fellow Americans: \n",
      "Tonight marks the eighth year I've come here to report on the State of the Union. And for this final one, I'm going to try to make it shorter. I know some of you are antsy to get back to Iowa. \n",
      "I also understand that because it's an election season, expectations for what we'll achieve this year are low. Still, Mr. Speaker, I appreciate the constructive approach you and the other leaders took at the end of last year to pass a budget and make tax cuts permanent for working families. So I hope we can work together this year on bipartisan priorities like criminal justice reform, and helping people who are battling prescription drug abuse. We just might surprise the cynics again. \n",
      "But tonight, I want to go easy on the traditional list of proposals for the year ahead. Don't worry, I've got plenty, from helping students learn to write computer code to personalizing medical treatments for patients. And I'll keep pushing for progress on the work that still needs doing. Fixing a broken immigration system. Protecting our kids from gun violence. Equal pay for equal work, paid leave, raising the minimum wage. All these things still matter to hardworking families; they are still the right thing to do; and I will not let up until they get done. \n",
      "But for my final address to this chamber, I don't want to talk just about the next year. I want to focus on the next five years, ten years, and beyond. \n",
      "I want to focus on our future. \n",
      "We live in a time of extraordinary change, change that's reshaping the way we live, the way we work, our planet and our place in the world. It's change that promises amazing medical breakthroughs, but also economic disruptions that strain working families. It promises education for girls in the most remote villages, but also connects terrorists plotting an ocean away. It's change that can broaden opportunity, or widen inequality. And whether we like it or not, the pace of this change will only accelerate. \n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "head mydir/sou/20160112.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting analysis of the textual content of the *State of the Union (SoU)* addresses by all US presidents was done in:\n",
    "\n",
    "-   [Alix Rule, Jean-Philippe Cointet, and Peter S. Bearman, Lexical shifts, substantive changes, and continuity in State of the Union discourse, 1790–2014, PNAS 2015 112 (35) 10837-10844; doi:10.1073/pnas.1512221112](http://www.pnas.org/content/112/35/10837.full).\n",
    "\n",
    "![](images/F5.large.png)\n",
    "\n",
    "[Image source](http://www.pnas.org/content/112/35/10837/F5.large.jpg)\n",
    "\n",
    "[Fig. 5](http://www.pnas.org/content/112/35/10837.full). A river network captures the flow across history of US political discourse, as perceived by contemporaries. Time moves along the x axis. Clusters on semantic networks of 300 most frequent terms for each of 10 historical periods are displayed as vertical bars. Relations between clusters of adjacent periods are indexed by gray flows, whose density reflects their degree of connection. Streams that connect at any point in history may be considered to be part of the same system, indicated with a single color.\n",
    "\n",
    "**You** *will be able to carry out such analyses and/or critically reflect on the mathematical statistical assumptions made in such analyses, as you learn more during your programme of study after successfully completing this course.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How was the `sou.tgz` file created?\n",
    "\n",
    "If you are curious, read: [http://lamastex.org/datasets/public/SOU/README.md](http://lamastex.org/datasets/public/SOU/README.md).\n",
    "\n",
    "Briefly, this is how a website with SOU was scraped by Paul Brouwers and adapted by Raazesh Sainudiin. A data scientist, and more generally a researcher interested in making statistical inference from data that is readily available online in a particular format, is expected to be comfortable with such *web-scraping tasks* (which can be done in more gracious and robust ways using specialised Python libraries). Such tasks also known as *Extract-Load-Transform (ELT)* operations are often time-consuming, expensive and the necessary first step towards extracting value from data.\n",
    "\n",
    "### A bit of bash and lynx to achieve the scraping of the state of the union addresses of the US Presidents,\n",
    "#### by Paul Brouwers\n",
    "\n",
    "The code below is mainly there to show how the text content of each state of the union address was scraped from the following URL:\n",
    "\n",
    "* [http://stateoftheunion.onetwothree.net/texts/index.html](http://stateoftheunion.onetwothree.net/texts/index.html)\n",
    "\n",
    "Such data acquisition tasks is usually the first and cucial step in a data scientist's workflow.\n",
    "\n",
    "We have done this and put the data in the distributed file system for easy loading into our notebooks for further analysis.  This keeps us from having to install unix programs like `lynx`, `sed`, etc. that are needed in the shell script below.\n",
    "\n",
    "\n",
    "```\n",
    "for i in $(lynx --dump http://stateoftheunion.onetwothree.net/texts/index.html | grep texts | grep -v index | sed 's/.*http/http/') ; do lynx --dump $i | tail -n+13 | head -n-14 | sed 's/^\\s\\+//' | sed -e ':a;N;$!ba;s/\\(.\\)\\n/\\1 /g' -e 's/\\n/\\n\\n/' > $(echo $i | sed 's/.*\\([0-9]\\{8\\}\\).*/\\1/').txt ; done\n",
    "```\n",
    "\n",
    "Or in a more atomic form:\n",
    "\n",
    "```\n",
    "for i in $(lynx --dump http://stateoftheunion.onetwothree.net/texts/index.html \\\n",
    "\n",
    "        | grep texts \\\n",
    "\n",
    "        | grep -v index \\\n",
    "\n",
    "        | sed 's/.*http/http/')\n",
    "\n",
    "do \n",
    "\n",
    "        lynx --dump $i \\\n",
    "\n",
    "               | tail -n+13 \\\n",
    "\n",
    "               | head -n-14 \\\n",
    "\n",
    "               | sed 's/^\\s\\+//' \\\n",
    "\n",
    "               | sed -e ':a;N;$!ba;s/\\(.\\)\\n/\\1 /g' -e 's/\\n/\\n\\n/' \\\n",
    "\n",
    "               > $(echo $i | sed 's/.*\\([0-9]\\{8\\}\\).*/\\1/').txt\n",
    "\n",
    "done\n",
    "```\n",
    "\n",
    "If you have time and are curious how each of the components in the above pipeline via `|` operators work, try to read `man echo`,  `man sed`,  `man grep`,  `man head`,  `man tail`, and  `man lynx` or `lynx --help`. If a command like `lynx` is not in your system, then you can install it with some work (mostly googling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "## uncomment by removing '#' in the next line and try executing this cell by pressing Ctrl-Enter to see if lynx is installed\n",
    "#lynx --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using `lynx` is not that difficult. Suppose you want to dump the contents of [https://lamastex.github.io/research/#available-student-projects](https://lamastex.github.io/research/#available-student-projects) to `stdout` or standard out, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "## uncomment by removing '#' in the next line and try executing this cell if lynx is installed\n",
    "#lynx --dump https://lamastex.github.io/research/#available-student-projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you had fun with BASH! Now let us put BASH to use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "lx_course_instance": "2023",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
